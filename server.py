import ast
import os
import shutil
import logging
from fastapi import FastAPI
from pydantic import BaseModel
from langchain_ollama import OllamaLLM
from langchain_core.prompts import PromptTemplate
from git import Repo

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()
llm = OllamaLLM(model="deepseek-coder", temperature=0.1)

class ReviewRequest(BaseModel):
    source: str

def get_code_chunks(code: str, file_path: str, max_lines: int = 150):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç –∫–æ–¥ –Ω–∞ —á–∞—Å—Ç–∏. –ï—Å–ª–∏ –±–ª–æ–∫ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, —Ä–µ–∂–µ—Ç –µ–≥–æ –ø–æ —Å—Ç—Ä–æ–∫–∞–º."""
    try:
        tree = ast.parse(code)
        chunks = []
        lines = code.splitlines()
        
        for node in tree.body:
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                start, end = node.lineno - 1, node.end_lineno
                content = "\n".join(lines[start:end])
                
                # –ï—Å–ª–∏ –±–ª–æ–∫ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –¥–µ–ª–∏–º –µ–≥–æ –Ω–∞ –ø–æ–¥-—á–∞—Å—Ç–∏
                if (end - start) > max_lines:
                    for i in range(0, len(lines[start:end]), max_lines):
                        sub_content = "\n".join(lines[start:end][i:i + max_lines])
                        chunks.append({
                            "name": f"{getattr(node, 'name', 'Block')} (—á–∞—Å—Ç—å {i//max_lines + 1})", 
                            "content": sub_content
                        })
                else:
                    chunks.append({"name": getattr(node, 'name', 'Block'), "content": content})
        
        if not chunks:
            # –ï—Å–ª–∏ ast –Ω–µ –Ω–∞—à–µ–ª —Å—Ç—Ä—É–∫—Ç—É—Ä (–ø—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∏–ø—Ç), —Ä–µ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –ø–æ —Å—Ç—Ä–æ–∫–∞–º
            for i in range(0, len(lines), max_lines):
                chunks.append({"name": f"Chunk {i//max_lines + 1}", "content": "\n".join(lines[i:i + max_lines])})
                
        return chunks
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {file_path}: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–∏–Ω—Ç–∞–∫—Å–∏—Å), —Ä–µ–∂–µ–º —Ñ–∞–π–ª –ø—Ä–æ—Å—Ç–æ –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        lines = code.splitlines()
        return [{"name": "Raw Chunk", "content": "\n".join(lines[i:i+max_lines])} for i in range(0, len(lines), max_lines)]

SYSTEM_PROMPT = """
–¢—ã ‚Äî Senior Developer. –ü—Ä–æ–≤–µ–¥–∏ –∞—É–¥–∏—Ç –∫–æ–¥–∞ –±–ª–æ–∫–∞ {name}.
–ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.
–§–æ—Ä–º–∞—Ç Markdown:
### üêû –ë–∞–≥–∏
### ‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
### üìä –°–ª–æ–∂–Ω–æ—Å—Ç—å
"""

@app.post("/review")
def review(req: ReviewRequest):
    work_dir = "temp_review"
    
    # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤
    if req.source.startswith("http"):
        if os.path.exists(work_dir): 
            shutil.rmtree(work_dir, ignore_errors=True)
        logger.info(f"–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {req.source}")
        try:
            Repo.clone_from(req.source, work_dir, depth=1)
        except Exception as e:
            return {"report": f"–û—à–∏–±–∫–∞ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {e}"}
        
        files = []
        for dp, dn, filenames in os.walk(work_dir):
            for f in filenames:
                if f.endswith('.py'):
                    files.append(os.path.join(dp, f))
    else:
        files = [req.source] if os.path.isfile(req.source) else []

    if not files:
        return {"report": "Python —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."}

    logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(files)}")
    full_report = []

    # 2. –¶–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞
    for file_path in files:
        logger.info(f"--- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file_path} ---")
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
            
            chunks = get_code_chunks(content, file_path)
            file_results = []
            
            for chunk in chunks:
                logger.info(f"–ê–Ω–∞–ª–∏–∑ –±–ª–æ–∫–∞: {chunk['name']}")
                prompt = PromptTemplate.from_template(SYSTEM_PROMPT).format(name=f"{file_path} -> {chunk['name']}")
                
                # –í—ã–∑–æ–≤ LLM (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)
                try:
                    res = llm.invoke(f"{prompt}\n\n–ö–æ–¥:\n{chunk['content']}")
                    file_results.append(f"#### –ë–ª–æ–∫: {chunk['name']}\n{res}")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ LLM –Ω–∞ –±–ª–æ–∫–µ {chunk['name']}: {e}")
            
            full_report.append(f"## –§–∞–π–ª: {file_path}\n" + "\n".join(file_results))
            
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file_path}: {e}")

    logger.info("–ê–Ω–∞–ª–∏–∑ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≤–µ—Ä—à–µ–Ω.")
    return {"report": "\n\n---\n\n".join(full_report)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
